{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOeK6U/XH1IMpqAdry6mhL/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install nltk\n","import nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4bLOlRauxP4","executionInfo":{"status":"ok","timestamp":1719911812828,"user_tz":-330,"elapsed":12240,"user":{"displayName":"Saksham Saini","userId":"04318623684321857455"}},"outputId":"dd58ec21-67b7-4ea8-8688-48e7e1aac5a8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIv9ICjmZVGr","executionInfo":{"status":"ok","timestamp":1719911817482,"user_tz":-330,"elapsed":1357,"user":{"displayName":"Saksham Saini","userId":"04318623684321857455"}},"outputId":"41b7f19a-cb76-4674-8f2e-de83b8b422e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","import pandas as pd\n","import string\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","import pickle\n"]},{"cell_type":"code","source":["\n","df = pd.read_csv('/content/spam.csv', encoding='latin-1')\n","df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n","df.columns = [\"label\", \"message\"]"],"metadata":{"id":"VuAHGPi7tG4l","executionInfo":{"status":"ok","timestamp":1719911378973,"user_tz":-330,"elapsed":610,"user":{"displayName":"Saksham Saini","userId":"04318623684321857455"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Preprocessing function\n","def preprocess_content(text):\n","    stemmer = PorterStemmer()\n","    nopunc = ''.join([char for char in text if char not in string.punctuation])\n","    words = word_tokenize(nopunc.lower())\n","    nostop = [stemmer.stem(word) for word in words if word not in stopwords.words('english') and word.isalpha()]\n","    return ' '.join(nostop)\n","\n","# Apply preprocessing\n","df['cleaned_text'] = df['message'].apply(preprocess_content)\n","tfidf = TfidfVectorizer()\n","X = tfidf.fit_transform(df['cleaned_text'])\n","y = df['label']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","# Train model\n","rf_model = RandomForestClassifier()\n","rf_model.fit(X_train, y_train)\n","\n","# Evaluate model\n","rf_preds = rf_model.predict(X_test)\n","rf_accuracy = accuracy_score(y_test, rf_preds)\n","rf_report = classification_report(y_test, rf_preds)\n","print(\"Random Forest Model:\")\n","print(f'Accuracy: {rf_accuracy:.4f}')\n","print(f'Classification Report:\\n{rf_report}\\n')\n","def predict_class(input_text):\n","    cleaned_input = preprocess_content(input_text)\n","    X_new = tfidf.transform([cleaned_input])\n","    return rf_model.predict(X_new)[0]\n","\n","# Test prediction\n","input_text = 'free entri wkli comp win fa cup final tkt may text fa receiv entri questionstd txt ratetc appli'\n","predicted_class = predict_class(input_text)\n","print(f\"Predicted class for '{input_text}': {predicted_class}\")\n","\n","# Pickle dump\n","with open('rf_model.pkl', 'wb') as f:\n","    pickle.dump(rf_model, f)\n","\n","with open('tfidf_vectorizer.pkl', 'wb') as f:\n","    pickle.dump(tfidf, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlCNgWAotPrP","executionInfo":{"status":"ok","timestamp":1719911857986,"user_tz":-330,"elapsed":33000,"user":{"displayName":"Saksham Saini","userId":"04318623684321857455"}},"outputId":"afff75d8-94cd-4918-a5d3-4aa2533abd87"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest Model:\n","Accuracy: 0.9740\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         ham       0.97      1.00      0.99       965\n","        spam       1.00      0.81      0.89       150\n","\n","    accuracy                           0.97      1115\n","   macro avg       0.99      0.90      0.94      1115\n","weighted avg       0.97      0.97      0.97      1115\n","\n","\n","Predicted class for 'free entri wkli comp win fa cup final tkt may text fa receiv entri questionstd txt ratetc appli': spam\n"]}]}]}